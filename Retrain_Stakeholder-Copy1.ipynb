{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: simplemma in /home/ec2-user/.local/lib/python3.8/site-packages (0.9.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --user simplemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# data modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, top_k_accuracy_score, f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "import simplemma\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from helpers import plot_confusion_matrix, get_top_features, fix_sdg_name\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD AND CONCATENATE THE DATABASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_comm, df_parl_ue], axis = 0)\n",
    "df = pd.concat([df, df_pol_it], axis = 0)\n",
    "df = pd.concat([df, df_giorn], axis = 0)\n",
    "df = pd.concat([df, df_crit], axis = 0)\n",
    "df = pd.concat([df, df_fin], axis = 0)\n",
    "df = pd.concat([df, df_ist], axis = 0)\n",
    "df = pd.concat([df, df_ong], axis = 0)\n",
    "df = pd.concat([df, df_uni], axis = 0)\n",
    "df = pd.concat([df, df_orgassoc], axis = 0)\n",
    "df = pd.concat([df, df_prof], axis = 0)\n",
    "df = pd.concat([df, df_manager], axis = 0)\n",
    "df = pd.concat([df, df_fornitori], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN AND PREPROCESS THE BIOGRAPHIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>categ</th>\n",
       "      <th>docs</th>\n",
       "      <th>docs_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ursula von der leyen</td>\n",
       "      <td>President of the @EU_Commission. Mother of sev...</td>\n",
       "      <td>politici</td>\n",
       "      <td>president of the eu_commission mother of seven...</td>\n",
       "      <td>ursula von der leyen president of the eu_commi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frans timmermans</td>\n",
       "      <td>Executive Vice-President for the European Gree...</td>\n",
       "      <td>politici</td>\n",
       "      <td>executive vice president for the european gree...</td>\n",
       "      <td>frans timmermans executive vice president for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>margrethe vestager</td>\n",
       "      <td>Executive Vice-President of the European Commi...</td>\n",
       "      <td>politici</td>\n",
       "      <td>executive vice president of the european commi...</td>\n",
       "      <td>margrethe vestager executive vice president of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>valdis dombrovskis</td>\n",
       "      <td>@EU_Commission Executive Vice-President for an...</td>\n",
       "      <td>politici</td>\n",
       "      <td>eu_commission executive vice president for an...</td>\n",
       "      <td>valdis dombrovskis  eu_commission executive vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>josep borrell fontelles</td>\n",
       "      <td>High Representative of the EU for Foreign Affa...</td>\n",
       "      <td>politici</td>\n",
       "      <td>high representative of the eu for foreign affa...</td>\n",
       "      <td>josep borrell fontelles high representative of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  \\\n",
       "1      ursula von der leyen   \n",
       "3          frans timmermans   \n",
       "5        margrethe vestager   \n",
       "7        valdis dombrovskis   \n",
       "11  josep borrell fontelles   \n",
       "\n",
       "                                          description     categ  \\\n",
       "1   President of the @EU_Commission. Mother of sev...  politici   \n",
       "3   Executive Vice-President for the European Gree...  politici   \n",
       "5   Executive Vice-President of the European Commi...  politici   \n",
       "7   @EU_Commission Executive Vice-President for an...  politici   \n",
       "11  High Representative of the EU for Foreign Affa...  politici   \n",
       "\n",
       "                                                 docs  \\\n",
       "1   president of the eu_commission mother of seven...   \n",
       "3   executive vice president for the european gree...   \n",
       "5   executive vice president of the european commi...   \n",
       "7    eu_commission executive vice president for an...   \n",
       "11  high representative of the eu for foreign affa...   \n",
       "\n",
       "                                            docs_name  \n",
       "1   ursula von der leyen president of the eu_commi...  \n",
       "3   frans timmermans executive vice president for ...  \n",
       "5   margrethe vestager executive vice president of...  \n",
       "7   valdis dombrovskis  eu_commission executive vi...  \n",
       "11  josep borrell fontelles high representative of...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cleaned_text(text):\n",
    "    \"\"\"\n",
    "    text cleaning.\n",
    "    Nota: \n",
    "    - valutare eliminazione caratteri non ascii\n",
    "    - valutare necessità stemming e lemmatization\n",
    "    \"\"\"\n",
    "    # Rimuovi testo della forma qualcosa.qualcosa (link ma anche 900.000)\n",
    "    text = re.sub(r'\\b[^\\s]*\\.[^\\s]*\\b', ' ', text)\n",
    "    # Rimuovi a capo\n",
    "    text = re.sub(r'\\\\n+', ' ', text)\n",
    "    # Rimuovi tutto ciò che non è alfanumerico o spazio\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Rimuovi RT\n",
    "    text = re.sub(r'^RT', ' ', text)\n",
    "    # Imposta lowercase\n",
    "    text = text.lower()\n",
    "    # Elimina spazi multipli\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "df['docs'] = df['description'].apply(lambda x: get_cleaned_text(x) )\n",
    "df['name']=df['name'].apply(lambda x: get_cleaned_text(x) )\n",
    "df['docs_name']=df['name']+' '+df['docs']\n",
    "df=df[df['name']!='non_trovato']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens=[nltk.word_tokenize(passage.lower()) for passage in text ]\n",
    "    return tokens\n",
    "\n",
    "def del_stopwords(stop_words,tokens):\n",
    "    a_filter=[]\n",
    "    for passage in tokens:\n",
    "        new_sentence = [word for word in passage if not word in stop_words]\n",
    "        a_filter.append(new_sentence)\n",
    "    return a_filter\n",
    "\n",
    "punctuations = list(string.punctuation)\n",
    "punctuations.append('’')\n",
    "punctuations.append('“')\n",
    "punctuations.append('”')\n",
    "punctuations.append('')\n",
    "punctuations.append('...')\n",
    "punctuations.append('``')\n",
    "punctuations.append(\"''\")\n",
    "\n",
    "def del_punct(punctuations,tokens):\n",
    "    b_filter=[]\n",
    "    for passage in tokens:\n",
    "        new_sentence = [word for word in passage if not word in punctuations]\n",
    "        b_filter.append(new_sentence)\n",
    "    return b_filter\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    c_filter=[]\n",
    "    for passage in tokens:\n",
    "        new_sentence=[simplemma.lemmatize(word, langdata) for word in passage]\n",
    "        c_filter.append(new_sentence)\n",
    "    return c_filter\n",
    "\n",
    "tokens=tokenizer(df['docs_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- APPLY LEMMATIZATION AND STOPWORDS ELIMINATION IN BOTH ITALIAN AND ENGLISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEMMAS BOTH ITA AND ENG\n",
    "stop_words=stopwords.words('italian')\n",
    "a_filter=del_stopwords(stop_words,tokens)\n",
    "stop_words=stopwords.words('english')\n",
    "a_filter=del_stopwords(stop_words,a_filter)\n",
    "b_filter=del_punct(punctuations,a_filter)\n",
    "\n",
    "try:\n",
    "    langdata = simplemma.load_data('it')\n",
    "    lemmas_a=lemmatize(b_filter)\n",
    "    langdata = simplemma.load_data('en')\n",
    "\n",
    "    lemmas_italiano_inglese=lemmatize(lemmas_a)\n",
    "except:\n",
    "    lemmas_italiano_inglese=b_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate tokens to pass them in the pipeline\n",
    "full_text=[]\n",
    "for sentence in lemmas_italiano_inglese:\n",
    "    sent=''\n",
    "    for word in sentence:\n",
    "        sent+=word+' '\n",
    "    sent=sent.strip()\n",
    "    full_text.append(sent)\n",
    "df['docs_name_lemmatized']=full_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDC CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sdg</th>\n",
       "      <th>feature</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>procurement</td>\n",
       "      <td>4.213957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>enelgroup</td>\n",
       "      <td>3.933026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>fabio</td>\n",
       "      <td>3.652096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sofia</td>\n",
       "      <td>3.652096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>oecd</td>\n",
       "      <td>3.371165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>confindustria</td>\n",
       "      <td>3.090235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>sales manager</td>\n",
       "      <td>2.809304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>enel</td>\n",
       "      <td>2.528374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>personal opinions</td>\n",
       "      <td>2.528374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>idee</td>\n",
       "      <td>2.528374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sdg            feature      coef\n",
       "0    1        procurement  4.213957\n",
       "1    1          enelgroup  3.933026\n",
       "2    1              fabio  3.652096\n",
       "3    1              sofia  3.652096\n",
       "4    1               oecd  3.371165\n",
       "5    1      confindustria  3.090235\n",
       "6    1      sales manager  2.809304\n",
       "7    1               enel  2.528374\n",
       "8    1  personal opinions  2.528374\n",
       "9    1               idee  2.528374"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       111\n",
      "           1       0.76      0.73      0.74        22\n",
      "\n",
      "    accuracy                           0.92       133\n",
      "   macro avg       0.85      0.84      0.85       133\n",
      "weighted avg       0.92      0.92      0.92       133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "cols=[\"investors\",\"critics\",\"media\",\"politicians\",\"ONG\",\"ORG\",\"Researchers\",\"Universities\",\"Top Managers\",\"Providers\"]\n",
    "\n",
    "for col in cols:\n",
    "    labelpos = df.loc[df['categ'] == col] \n",
    "    labelneg = df.loc[df['categ'] != col]\n",
    "    \n",
    "    #resample\n",
    "    labelneg = df.loc[df['categ'] != col].sample(n=min(labelneg.shape[0],5*labelpos.shape[0]))\n",
    "    labelneg['categ'] = 0 \n",
    "    labelpos['categ'] = 1 \n",
    "    balanced_dataset = pd.concat([labelneg, labelpos], axis = 0)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    balanced_dataset['docs_name_lemmatized'].values,\n",
    "    balanced_dataset['categ'].values,\n",
    "    test_size = .1,\n",
    "    random_state = 42\n",
    "    )\n",
    "    \n",
    "    pipe = Pipeline([\n",
    "    ('vectoriser', CountVectorizer(ngram_range = (1, 2))),\n",
    "    ('selector', SelectKBest(chi2, k = 200)),\n",
    "    ('clf',SGDClassifier(**params)),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_hat = pipe.predict(X_test)\n",
    "    accuracy_sc = accuracy_score(y_test, y_hat)\n",
    "\n",
    "    df_lambda = get_top_features(pipe['vectoriser'], pipe['clf'], pipe['selector'], top_n = 20)\n",
    "    display(df_lambda.head(10))\n",
    "\n",
    "    filename_model=col+'_pipe_model.sav'\n",
    "    #pickle.dump(pipe, open('models/to_use/'+filename_model, 'wb'))\n",
    "    print(classification_report(y_test, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
